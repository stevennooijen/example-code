{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series classification\n",
    "\n",
    "In this notebook I demonstrate how to do a classification task on panel data.\n",
    "\n",
    "A classic example for this case is predicting churn: for each time period, build a model that predicts the target variable 1 (churn) or 0 (not churn) based on previous time period data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "\n",
    "Things to pay special attention to:\n",
    "\n",
    "- Target definition: are you forecasting an event one period ahead, or multiple periods ahead?\n",
    "- Cross validation: what time periods do you want to use for model selection, and which for testing?\n",
    "- Class unbalances: is each class represented equally? If not sample to remove redundancy and boost model performance.\n",
    "\n",
    "All are demonstrated in this notebooks example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "For this demo let's play with a small panel dataset called [Cornwell and Rupert Returns to Schooling Data](http://people.stern.nyu.edu/wgreene/Econometrics/PanelDataSets.htm). The data contains multivariate time series data on 595 Individuals, measured over 7 Years. \n",
    "\n",
    "One of the variables is whether the person was married or not `MS == 1`. In this exercise we are going to predict if someone is getting married, which is defined as: `MS_t-1 == 0 & MS_t == 1`.\n",
    "\n",
    "### 1. Preprocessing data\n",
    "\n",
    "First import the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/cornwell_rupert.csv').rename(columns=lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then select a subset of unmarried people, and define our target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unmarried = (\n",
    "    df\n",
    "    .loc[df['ID'].isin(df.loc[(df['YEAR']==1) & (df['MS']==0)]['ID'])]  # subset only unmarried population\n",
    "    .assign(MS_previous = lambda x: x.groupby('ID')['MS'].shift(1)) \n",
    "    .assign(got_married = lambda x: x['MS'] > x['MS_previous'])  # check if married that year\n",
    "    .drop('MS_previous', axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to prepare our dataframe such that at each time period, we have:\n",
    "- One record per individual\n",
    "- The target variable whether someone got married that year (1 or 0)\n",
    "- Various features that are based on previous time periods (married last 1 period, 3 periods, 6 periods, ...)\n",
    "\n",
    "For the time based features, we need a function that calculates these given any original feature and the required time lag or shift. \n",
    "\n",
    "In this example, we are only going to use the last year to predict the next year. This means we are shifting all our featuers by 1 period. Basically for every `X`, we are now making sure `X_t-1` is on the same row as the `y` that we are predicting. This is handy as it will allow for simple cross validation iterators later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to lag features a specified number of periods\n",
    "def shift_features(dataframe_in, *features, periods_to_shift=1, group_var='ID'):\n",
    "    \"\"\"Replaces features in a dataframe by their requested lag. \n",
    "\n",
    "    Args:\n",
    "        dataframe_in: Input dataframe with features to lag\n",
    "        features: List of features to lag\n",
    "        periods_to_shift: Number of periods to shift each feature. Default is 1.\n",
    "        group_var: Variable indicating the grouping within which to shift.\n",
    "\n",
    "    Yields:\n",
    "        dataframe_out: new dataframe with lagged features\n",
    "    \"\"\"\n",
    "    dataframe_out = dataframe_in.copy()\n",
    "    \n",
    "    for feature in features:\n",
    "        feature_name = feature+'_lag'+str(periods_to_shift)\n",
    "        dataframe_out[feature_name] = dataframe_out.groupby(group_var)[feature].shift(periods_to_shift)\n",
    "        dataframe_out.drop(feature, axis=1, inplace=True)\n",
    "\n",
    "    return dataframe_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply and check if all went well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>got_married</th>\n",
       "      <th>ID</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MS_lag1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    got_married  ID  YEAR  MS_lag1\n",
       "21        False   4     1      NaN\n",
       "22        False   4     2      0.0\n",
       "23        False   4     3      0.0\n",
       "24        False   4     4      0.0\n",
       "25        False   4     5      0.0\n",
       "26        False   4     6      0.0\n",
       "27        False   4     7      0.0\n",
       "70        False  11     1      NaN\n",
       "71        False  11     2      0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shift all features except indices and the target\n",
    "features = [col for col in df_unmarried.columns if col not in ['ID', 'YEAR', 'got_married']]\n",
    "X_all = shift_features(df_unmarried, *features)\n",
    "\n",
    "X_all.head(9)[['got_married', 'ID', 'YEAR', 'MS_lag1']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good, but now we have `NaN` values for the first year. Remove these from the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = X_all.loc[X_all['YEAR'] > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. This is the data we will be using for our model. As a final check, let's take a look if there is any skew in our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>got_married</th>\n",
       "      <th>n_records</th>\n",
       "      <th>perc_married</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEAR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>105</td>\n",
       "      <td>2.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>105</td>\n",
       "      <td>2.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>105</td>\n",
       "      <td>3.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>105</td>\n",
       "      <td>1.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>105</td>\n",
       "      <td>1.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>0.952381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      got_married  n_records  perc_married\n",
       "YEAR                                      \n",
       "2               3        105      2.857143\n",
       "3               3        105      2.857143\n",
       "4               4        105      3.809524\n",
       "5               2        105      1.904762\n",
       "6               2        105      1.904762\n",
       "7               1        105      0.952381"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def print_count_per_year(df):\n",
    "    return (\n",
    "        df\n",
    "        .groupby('YEAR')\n",
    "        .apply(lambda x: pd.Series({\n",
    "            'got_married' : x['got_married'].sum(),\n",
    "            'n_records' : len(x)\n",
    "        }))\n",
    "        .assign(perc_married = lambda x: x['got_married'] / x['n_records'] * 100)\n",
    "    )\n",
    "\n",
    "print_count_per_year(X_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoa! This is very skewed. Keeping it like this will make it very hard for a model to predict the right outcome. For example, a model that always predicts `got_married == 0` will be very hard to beat in terms of accuracy. \n",
    "\n",
    "A skew like this is quite normal for a churn case prediction problem. The solution is to sample in each of the periods to make the balance more equal. This also reduces redundancy caused by ohterwise including the same individual (`'ID'`) multiple times in the data set (1 for each year, so 7 times!).\n",
    "\n",
    "In below code, we randomly pick 5 of the class of people that didn't get married for each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>got_married</th>\n",
       "      <th>n_records</th>\n",
       "      <th>perc_married</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEAR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>37.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>37.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>44.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>28.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>28.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>16.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      got_married  n_records  perc_married\n",
       "YEAR                                      \n",
       "2               3          8     37.500000\n",
       "3               3          8     37.500000\n",
       "4               4          9     44.444444\n",
       "5               2          7     28.571429\n",
       "6               2          7     28.571429\n",
       "7               1          6     16.666667"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sampled = (\n",
    "    X_all\n",
    "    .groupby(['YEAR', 'got_married'], group_keys=False)\n",
    "    .apply(lambda x: x.sample(min(len(x), 5), random_state=777))\n",
    ")\n",
    "\n",
    "print_count_per_year(X_sampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can make a time series classification model on who is getting married each period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45, 24), (45,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X_sampled.copy()\n",
    "y = X.pop('got_married')\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Setting up the cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 7 years of data to be used. Think about how you want to do model selection and evaluation. For example:\n",
    "- **Train_set**: years 1 to 5. Cross validation will look as follows:\n",
    "    - The first two years are used for the first training set (`X` from period 1, `y` from period 2)\n",
    "    - That means the first validation fold could be year 3.\n",
    "    - Such that 3 fold time series cross validation is possible (year 3, 4 and 5).\n",
    "- **Model evaluation**: years 6 and 7\n",
    "\n",
    "Note that in the case we defined our target as predicting marriage 2 months ahead, we would have 1 gap month, and the first validation fold would be year 4. In that case, only 2 folds can be used for the cross validation.\n",
    "\n",
    "For training we use the *entire* history untill time `t-1` to get as much training data as possible (the number of data points is pretty small, so we need as much as possible). In other cases, it could make sense to only use the last previous year of data for training. This could be a good option in the scenario that you think old data is not relevant for the current time period anymore, for example because the world changed.\n",
    "\n",
    "We might be able to use `sklearn.model_selection.TimeSeriesSplit`, but here I like to demonstrate how to create a custom cross validation iterator to be used in `grid_search`. We want to predict let's say period `t` (= test data) based on the values of period `t-1, t-2, t-3, ...` (= train data). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeseries_cv(x, split_by, start_period=1, stop_period=None):\n",
    "    \"\"\"Cross validation iterator which predicts a period based on all previous periods.\n",
    "\n",
    "    Args:\n",
    "        x: DataFrame to iterate over.\n",
    "        split_by: Name of the time column or index level.\n",
    "        start_period: First period nr that is used for validation. Default of 1 means 1 period is used for training.\n",
    "        stop_period: Last period nr that is used for validation. By setting this data can kept apart for evaluation.\n",
    "\n",
    "    Yields:\n",
    "        train_index, test_index\n",
    "    \"\"\"\n",
    "    \n",
    "    x = x.reset_index()\n",
    "    unique = x[split_by].unique()[start_period:stop_period]\n",
    "    \n",
    "    for value in unique:\n",
    "        yield x[x[split_by] < value].index.values, x[x[split_by] == value].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# define generator for creating train and test data folds\n",
    "cv_splitter_train = timeseries_cv(X, 'YEAR', stop_period=4)\n",
    "cv_splitter_test = timeseries_cv(X, 'YEAR', start_period=4)\n",
    "\n",
    "# print('number of train/test folds:', (len(list(cv_splitter_train)), len(list(cv_splitter_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates 3 train folds and 2 test folds (check for yourself by uncommenting the last `list` line).\n",
    "\n",
    "This satisfies our wishes: \n",
    "- For **model selection** we use folds where years 3, 4 and 5 are used for validation. Years 1 and 2 are reserved for training.\n",
    "- For **model evaluation** we use folds with actuals from years 6 and 7 to compare with our model predictions.\n",
    "\n",
    "### 3. Model selection\n",
    "\n",
    "Now let's do a grid search to select our model. We hand the grid search algorithm X, y and a cross validation iterator. The iterator will then select the indices for each of the folds and subset the X and y data accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': 2, 'n_estimators': 50} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/terminator/miniconda3/envs/example-code/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = RandomForestClassifier(random_state=707)  # set random seed to reproduce results\n",
    "\n",
    "params = {'max_depth': [2, 3, 4, 10], \n",
    "          'n_estimators' : [10, 20, 50]}\n",
    "\n",
    "grid_search = GridSearchCV(model, scoring='precision', param_grid=params, n_jobs=-1, cv=cv_splitter_train)\n",
    "\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print('Best params:', grid_search.best_params_, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('All grid search results:')\n",
    "\n",
    "# for comb in zip(grid_search.cv_results_['params'], grid_search.cv_results_['mean_test_score']):\n",
    "#     print(comb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model evaluation\n",
    "\n",
    "We are going to evaluate the model on the last 2 periods. This means for every period we have to retrain the model, score with it and get the results. The results over the 2 periods are then averaged to get the final evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train/test obs in fold = (32, 7)\n",
      "Precision: 0.5\n",
      "Confusion matrix: \n",
      " [[4 1]\n",
      " [1 1]]\n",
      "Number of train/test obs in fold = (39, 6)\n",
      "Precision: 0.0\n",
      "Confusion matrix: \n",
      " [[4 1]\n",
      " [1 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score\n",
    "\n",
    "model = grid_search.best_estimator_\n",
    "\n",
    "cv_splitter_test = timeseries_cv(X, 'YEAR', start_period=4)\n",
    "\n",
    "# loop over de test data folds\n",
    "for train_ind, test_ind in cv_splitter_test:\n",
    "    \n",
    "    print('Number of train/test obs in fold =', (len(train_ind), len(test_ind)))\n",
    "    \n",
    "    # select test data for the selected fold\n",
    "    X_train, y_train = X.iloc[train_ind], y.iloc[train_ind]\n",
    "    X_test, y_test = X.iloc[test_ind], y.iloc[test_ind]\n",
    "    \n",
    "    # fit and predict for the selected fold\n",
    "    model.fit(X_train, y_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # report on error metrics\n",
    "    print('Precision:', precision_score(y_test, y_test_pred))\n",
    "    print('Confusion matrix: \\n', confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the evaluation metrics above we see:\n",
    "* The first fold had 32 observations (years 2, 3, 4 and 5), and 7 observations in year 6 to test.\n",
    "* The 7 observations from year 6 are added to the training data for the last evaluation fold testing on year 7.\n",
    "* The model classified one person correctly in the first fold (bottom-right corner of the confusion matrix).\n",
    "* The overall precision we can report is the average precision over evaluation folds: `(0.5 + 0) / 2 = 0.25`.\n",
    "\n",
    "Note: we made a choice here to split our data in a *model selection* (years 2-5) and *model evaluation* part (years 6 & 7). An alternative could be to do *rolling evaluation* instead, as described in notebook `00-time-series-basics`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
